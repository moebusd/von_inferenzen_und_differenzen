{"metadata":{"colab":{"collapsed_sections":["CNT53ojUq6Wz","2Fam3X6jySMA","lo-HHwniySMD","Zd4iuyMdySMF","ZlHbTvjeyeJC","MYR0C4Qbymln","2d8PvclYGP5t","2mipguse6YyL","JGC7TDUWpKxa","KaBuL5wqNaS-","njQh2R1Oh2MD","hTzwNfnLx-AZ","aYc173tSlj4P","qlEXAgEKoZpf","qAXoLBkaQd5N","c4bL0xuqEP1v"],"name":"MASTER Topic Modeling Pipeline Tagungsband","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3 (ipykernel)","language":"python"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Von Inferenzen und Differenzen\n## Ein Vergleich von Topic-Modeling-Engines auf Grundlage historischer Korpora\n<i>von Tobias Hodel, Dennis Möbus und Ina Serif</i>","metadata":{}},{"cell_type":"markdown","source":"## Einführung\n\nSie befinden sich nun in einer Programmierkonsole, die auf einer virtuellen Maschine, also nicht auf Ihrem Rechner ausgeführt wird. In den folgenden \"Zellen\" wechseln sich Textbausteine und Programmierzellen ab, in denen Sie Programmcode ausführen können. Alles ist soweit vorbereitet, dass Sie nur in der oberen linken Ecke einer Zelle zwischen den eckigen Klammern -> [  ] das Play-Symbol klicken müssen, das erscheint, wenn Sie mit der Maus über die Klammern fahren. Die Zellen müssen strikt in der Reihenfolge von oben nach unten ausgeführt werden, da spätere Zellen auf die Variablen voriger aufbauen. In einigen Zellen finden Sie Parameter, die Sie einstellen können - probieren Sie ruhig alles aus und vergleichen Sie die Ergebnisse.\n","metadata":{"id":"hQZPpSk87kPP"}},{"cell_type":"markdown","source":"## Installation von Java und Mallet","metadata":{"tags":[],"jp-MarkdownHeadingCollapsed":true}},{"cell_type":"code","source":"! java -version\n!wget http://mallet.cs.umass.edu/dist/mallet-2.0.8.zip\n!unzip -q mallet-2.0.8.zip\n!mallet-2.0.8/bin/mallet\nmallet_path = 'mallet-2.0.8/bin/mallet' \n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Installation und Import benötigter Pakete","metadata":{"jp-MarkdownHeadingCollapsed":true,"tags":[]}},{"cell_type":"code","source":"!pip install -i https://test.pypi.org/simple/ topic-modeling-moebusd==0.27\n!pip install pandas\n!pip install gensim==3.8.3\n!pip install plotly\nimport os\nimport pandas as pd\nimport plotly.express as px\nfrom topic_modeling import remove_stopwords_by_threshold\nfrom topic_modeling import remove_stopwords_by_list\nfrom topic_modeling import lemmatization","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Import der Daten\n\nBitte gewünschte Zelle ausführen!","metadata":{}},{"cell_type":"markdown","source":"<i>Mittelalterliche Handschriften laden</i>","metadata":{}},{"cell_type":"code","source":"chunksize = 500 # Länge der Chunks in Wörtern, default ist 500, mögliche Werte: 250, 500, 1000, 2500, 5000\n                # möglich ist auch die Angabe \"fulltext\" (mit Anführungszeichen!)\n\nname_dataset = 'twinger_chronik_chunked_'+str(chunksize)+'_Wörter' \ndataframeimport = pd.read_pickle(name_dataset) \nraw_data = dataframeimport.values.tolist() # Umwandlung des Dataframes in eine Liste\ndata = [[word for word in line[1].split()] for line in raw_data] # Tokenisierung\nprint(data[0][:9])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<i>Schweizer Ratsprotokolle des 19. Jahrhunderts laden</i>","metadata":{}},{"cell_type":"code","source":"files_resolutions = 'https://raw.githubusercontent.com/DHBern/TopicModeling/main/Data/dataframes/data_stazh_tkr_df'\ndataframeimport = pd.read_pickle(files_resolutions)\nname_dataset = 'resolutions'\nraw_data = dataframeimport.values.tolist() # Umwandlung des Dataframes in eine Liste\ndata = [[word for word in line[1].split()] for line in raw_data] # Tokenisierung\nprint(data[0][:9])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<i>Oral-History-Interviews des 20. Jahrhunderts laden</i>","metadata":{}},{"cell_type":"code","source":"chunksize = 25 # Länge der Chunks in Sätzen, default ist 25, mögliche Werte: 1, 5, 10, 25, 50\n\nname_dataset = 'all_transcripts_df_sentences_clean_normalized_'+str(chunksize)+'sentence(s)_NEW'\ndataframeimport = pd.read_pickle(name_dataset)\nraw_data = dataframeimport.values.tolist() # Umwandlung des Dataframes in eine Liste\ndata = [[word for word in line[1].split()] for line in raw_data] # Tokenisierung\nprint(data[0][:10])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Preprocessing","metadata":{}},{"cell_type":"markdown","source":"### Entfernen von Stopwords durch Stoplist","metadata":{}},{"cell_type":"code","source":"if 'twinger' in name_dataset:\n    stoplist = open('gmh_stopwords_edited.txt', encoding='UTF-8', mode='r').read().split()\nelse:\n    stoplist = open('german_stopwords_full_BE_MOD Topics_UTF-8.txt', encoding='UTF-8', mode='r').read().split()\n\ndata_nostops = remove_stopwords_by_list(data, stoplist)\nprint(data_nostops[:9])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Entfernen von Stopwords durch Threshold","metadata":{}},{"cell_type":"code","source":"threshold = 0.001 # Alle Wörter oberhalb dieses prozentualen Anteils am Text werden heraus gefiltert\n\ndata_nostops = remove_stopwords_by_threshold(data, threshold)\nprint(data_nostops[:9])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Lemmatisierung (nur für Oral-History-Interviews)","metadata":{}},{"cell_type":"code","source":"# Zusätzliche Pakete installieren\n!pip install --upgrade spacy\n!pip install https://github.com/explosion/spacy-models/releases/download/de_core_news_lg-3.2.0/de_core_news_lg-3.2.0.tar.gz\nimport spacy","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_lemmatized = lemmatization(data_nostops, 3)    # als erstes Argument kann auch \"data\" übergeben werden, wenn nur lemmatisiert werden soll, \nprint(data_lemmatized[:9])                          # ohne vorher Stopwords zu entfernen\n                                                    # als zusätzliches Argument kann allowed_postags=['NN', 'PN', 'ADJ', 'ADV', 'VB'] angegeben werden, \n                                                    # wobei die Postags in der Liste auch auf weniger reduziert werden können","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Topic Training","metadata":{}},{"cell_type":"markdown","source":"### Gensim (= Variational Bayes)","metadata":{}},{"cell_type":"code","source":"from topic_modeling import topic_training_gensim\nlda_model_gensim, doc_tops_gensim, topwords_gensim = topic_training_gensim(data_nostops, name_dataset, 'moebusd', 50, passes_gensim=5, iterations_gensim=10)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Mallet (= Gibbs-Sampling)","metadata":{}},{"cell_type":"code","source":"from topic_modeling import topic_training_mallet\nlda_model_mallet, doc_tops_mallet, topwords_mallet = topic_training_mallet(data, name_dataset, 'moebusd', 50, mallet_path, optimize_interval_mallet=50, iterations_mallet=500)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Topic-Listen ausgeben","metadata":{}},{"cell_type":"markdown","source":"### Gensim","metadata":{}},{"cell_type":"code","source":"from topic_modeling import print_topics_gensim\nprint_topics_gensim(topwords_gensim, 15, name_dataset)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Mallet","metadata":{}},{"cell_type":"code","source":"from topic_modeling import print_topics_mallet\nprint_topics_mallet(topwords_mallet, 15, name_dataset)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Evaluation und Visualisierung","metadata":{}},{"cell_type":"code","source":"from topic_modeling import doc_top_heatmap\n\ndoc_top_heatmap(doc_tops_mallet, topwords_mallet, raw_data, split_index=1) # Welche Bestandteile der Signatur für Y-Achse?","metadata":{},"execution_count":null,"outputs":[]}]}